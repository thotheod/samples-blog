{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Depedencies\n",
    "\n",
    "Install the required dependencies as they are described in the requirements.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use OpenAI API\n",
    "\n",
    "Before we call any API, we need to retrieve the required values from the `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure OpenAI API Base: https://cog-ilecskbcfhj6i.openai.azure.com/\n",
      "Remote OpenAI API completions URL: https://cog-ilecskbcfhj6i.openai.azure.com//openai/deployments/turbochatmodel/chat/completions?api-version=2023-09-01-preview\n"
     ]
    }
   ],
   "source": [
    "import json     # Import the json module to work with JSON data\n",
    "import requests # Import the requests module to send HTTP requests\n",
    "import os       # Import the os module to work with the operating system\n",
    "\n",
    "# Import the load_dotenv function from the dotenv module to load environment variables from a .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file. If successful, print the Azure OpenAI API endpoint\n",
    "if load_dotenv():\n",
    "    print(\"Azure OpenAI API Base: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    # If the .env file could not be loaded, print a message indicating that the Azure OpenAI API endpoint was not found\n",
    "    print(\"Azure OpenAI API Endpoint not found.\")\n",
    "    \n",
    "# Get the values of the environment variables\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    "\n",
    "\n",
    "# url = AZURE_OPENAI_ENDPOINT + \"/openai/deployments/\" + AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME + \"/completions?api-version=\" + AZURE_OPENAI_API_VERSION\n",
    "url = AZURE_OPENAI_ENDPOINT + \"/openai/deployments/\" + AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME + \"/chat/completions?api-version=\" + AZURE_OPENAI_API_VERSION\n",
    "\n",
    "print(f'Remote OpenAI API completions URL: {url}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we constructed the required URL that we will use, let's call it. We need to pass the API key in the HTTP header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8wnfkbSJHs2lqruAO3zSZ15Pe5gzB\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1709024656,\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Why don't scientists trust atoms? Because they make up everything!\"\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      },\n",
      "      \"logprobs\": null\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 13,\n",
      "    \"completion_tokens\": 13,\n",
      "    \"total_tokens\": 26\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# r = requests.post(url, headers={\"api-key\": AZURE_OPENAI_API_KEY}, json={\"max_tokens\": 40, \"prompt\": \"tell me a joke\", \"temperature\": 1.0})\n",
    "r = requests.post(url, headers={\"api-key\": AZURE_OPENAI_API_KEY}, json={\"messages\":[{\"role\": \"user\", \"content\": \"tell me a quick joke\"}]})\n",
    "\n",
    "\n",
    "print(json.dumps(r.json(), indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use OpenAI API Python Library\n",
    "In the next snippet we are going to issue the same request but without using the http request directly. Instead we will use the Python `openai` library, which as we will see, simplifies somehow our code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Why did the tomato turn red? Because it saw the salad dressing!\n",
      "CompletionUsage(completion_tokens=14, prompt_tokens=13, total_tokens=27)\n"
     ]
    }
   ],
   "source": [
    "# Import the AzureOpenAI class from the openai module\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Create an instance of the AzureOpenAI class, passing in the Azure endpoint, API key, and API version from environment variables\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    ")\n",
    "\n",
    "# Call the chat.completions.create method on the client object, passing in the model name from an environment variable and a list of messages\n",
    "response = client.chat.completions.create(\n",
    "    model = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"),\n",
    "    messages = [{\"role\" : \"assistant\", \"content\" : \"Tell me a quick joke\"}],\n",
    ")\n",
    "\n",
    "# Print the response from the API call\n",
    "# print(response)\n",
    "\n",
    "print('Response: ' + response.choices[0].message.content)\n",
    "print(response.usage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Langchain\n",
    "\n",
    "Langchain simplifies the process of building applications powered by large language models. It supports **Python** and Javascript / Typescript, but in this post, we focus on Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Azure OpenAI Endpoint: https://cog-ilecskbcfhj6i.openai.azure.com/\n",
      "AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME: turbochatmodel\n",
      "Once upon a time, there was a little girl named Lily who lived in a small village. She loved to spend her days exploring the nearby forest, where she would often encounter all sorts of animals, from squirrels to rabbits to deer.\n",
      "\n",
      "One day, while wandering through the forest, Lily heard a strange noise coming from a nearby bush. Curious, she cautiously approached the bush and peeked inside. To her surprise, she found a tiny, injured bird lying on the ground.\n",
      "\n",
      "Feeling sorry for the poor bird, Lily decided to take it home and nurse it back to health. She spent the next few days caring for the bird, feeding it, and keeping it warm until it was strong enough to fly away on its own.\n",
      "\n",
      "As the days passed, Lily continued to explore the forest, but now she did so with a renewed sense of wonder and appreciation for all the creatures that lived there. And whenever she encountered an injured or lost animal, she knew just what to do to help it.\n",
      "\n",
      "From that day on, Lily became known as the village's very own animal whisperer, and she spent the rest of her days helping animals in need and exploring the wonders of the natural world.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import AzureOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"No file .env found\")\n",
    "\n",
    "## Create an instance of Azure OpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    ")\n",
    "\n",
    "print(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME: \" + os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"))\n",
    "\n",
    "\n",
    "# Define the prompt \n",
    "msg = HumanMessage(content=\"Tell me short story?\")\n",
    "\n",
    "# Call the API\n",
    "r = llm.invoke([msg])\n",
    "\n",
    "# Print the response\n",
    "print(r.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aoai-sample-01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
