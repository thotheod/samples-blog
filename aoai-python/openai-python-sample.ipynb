{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Depedencies\n",
    "\n",
    "Install the required dependencies as they are described in the requirements.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use OpenAI API\n",
    "\n",
    "Before we call any API, we need to retrieve the required values from the `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure OpenAI API Base: https://cog-ilecskbcfhj6i.openai.azure.com/\n",
      "Remote OpenAI API completions URL: https://cog-ilecskbcfhj6i.openai.azure.com//openai/deployments/turbochatmodel/chat/completions?api-version=2023-09-01-preview\n"
     ]
    }
   ],
   "source": [
    "import json     # Import the json module to work with JSON data\n",
    "import requests # Import the requests module to send HTTP requests\n",
    "import os       # Import the os module to work with the operating system\n",
    "\n",
    "# Import the load_dotenv function from the dotenv module to load environment variables from a .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file. If successful, print the Azure OpenAI API endpoint\n",
    "\n",
    "\n",
    "if load_dotenv():\n",
    "    print(\"Azure OpenAI API Base: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    # If the .env file could not be loaded, print a message indicating that the Azure OpenAI API endpoint was not found\n",
    "    print(\"Azure OpenAI API Endpoint not found.\")\n",
    "    \n",
    "# Get the values of the environment variables\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    "\n",
    "\n",
    "# url = AZURE_OPENAI_ENDPOINT + \"/openai/deployments/\" + AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME + \"/completions?api-version=\" + AZURE_OPENAI_API_VERSION\n",
    "url = AZURE_OPENAI_ENDPOINT + \"/openai/deployments/\" + AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME + \"/chat/completions?api-version=\" + AZURE_OPENAI_API_VERSION\n",
    "\n",
    "print(f'Remote OpenAI API completions URL: {url}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we constructed the required URL that we will use, let's call it. We need to pass the API key in the HTTP header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8wnfkbSJHs2lqruAO3zSZ15Pe5gzB\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1709024656,\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Why don't scientists trust atoms? Because they make up everything!\"\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      },\n",
      "      \"logprobs\": null\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 13,\n",
      "    \"completion_tokens\": 13,\n",
      "    \"total_tokens\": 26\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# r = requests.post(url, headers={\"api-key\": AZURE_OPENAI_API_KEY}, json={\"max_tokens\": 40, \"prompt\": \"tell me a joke\", \"temperature\": 1.0})\n",
    "r = requests.post(url, headers={\"api-key\": AZURE_OPENAI_API_KEY}, json={\"messages\":[{\"role\": \"user\", \"content\": \"tell me a quick joke\"}]})\n",
    "\n",
    "\n",
    "print(json.dumps(r.json(), indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use OpenAI API Python Library\n",
    "In the next snippet we are going to issue the same request but without using the http request directly. Instead we will use the Python `openai` library, which as we will see, simplifies somehow our code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: What's the difference between a poorly dressed man on a trampoline and a well-dressed man on a trampoline? \n",
      "\n",
      "Attire.\n",
      "CompletionUsage(completion_tokens=28, prompt_tokens=13, total_tokens=41)\n"
     ]
    }
   ],
   "source": [
    "# Import the AzureOpenAI class from the openai module\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Create an instance of the AzureOpenAI class, passing in the Azure endpoint, API key, and API version from environment variables\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    ")\n",
    "\n",
    "# Call the chat.completions.create method on the client object, passing in the model name from an environment variable and a list of messages\n",
    "response = client.chat.completions.create(\n",
    "    model = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"),\n",
    "    messages = [{\"role\" : \"assistant\", \"content\" : \"Tell me a quick joke\"}],\n",
    ")\n",
    "\n",
    "# Print the response from the API call\n",
    "# print(response)\n",
    "\n",
    "print('Response: ' + response.choices[0].message.content)\n",
    "print(response.usage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Langchain\n",
    "\n",
    "Langchain simplifies the process of building applications powered by large language models. It supports **Python** and Javascript / Typescript, but in this post, we focus on Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure OpenAI API Base: https://cog-ilecskbcfhj6i.openai.azure.com/\n",
      "AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME: turbochatmodel\n",
      "Once upon a time, there was a little girl named Lily who lived in a small village at the edge of a forest. One day, as she was playing in the forest, she stumbled upon a magical flower. The flower was glowing in a beautiful shade of blue and when Lily picked it up, she felt a strange sensation coursing through her body.\n",
      "\n",
      "As she made her way back home, she noticed that the people in her village were acting out of character. They were angry, short-tempered and seemed to be on the brink of a fight. Lily knew that something was wrong and decided to investigate.\n",
      "\n",
      "She made her way back to the forest and found a group of mischievous fairies who were causing all the trouble. They had cast a spell on the village, causing everyone to become irritable and angry. Lily knew that she had to do something to stop the fairies.\n",
      "\n",
      "With the magical flower in her hand, she confronted the fairies and demanded that they remove the spell. At first, the fairies refused and threatened to cast a spell on Lily too, but she stood her ground and refused to back down.\n",
      "\n",
      "Finally, the fairies relented and removed the spell. The village returned to its peaceful state and everyone was happy once again. From that day on, Lily was known as the hero of the village and was respected by all.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import AzureOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if load_dotenv():\n",
    "    print(\"Azure OpenAI API Base: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    # If the .env file could not be loaded, print a message indicating that the Azure OpenAI API endpoint was not found\n",
    "    print(\"Azure OpenAI API Endpoint not found.\")\n",
    "\n",
    "## Create an instance of Azure OpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    ")\n",
    "\n",
    "print(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME: \" + os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"))\n",
    "\n",
    "\n",
    "# Define the prompt \n",
    "msg = HumanMessage(content=\"Tell me short story?\")\n",
    "\n",
    "# Call the API\n",
    "r = llm.invoke([msg])\n",
    "\n",
    "# Print the response\n",
    "print(r.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aoai-sample-01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
